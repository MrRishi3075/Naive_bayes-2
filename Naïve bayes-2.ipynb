{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0b93b4-e57d-49a8-aa7c-bf3f9c47cb46",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb5b27-9a00-4085-aec5-0d4ee3c00d93",
   "metadata": {},
   "source": [
    "##### To find the probability that an employee is a smoker given that he/she uses the health insurance plan, you can use conditional probability. The notation for this probability is P(Smoker | Uses insurance). The formula for conditional probability is:\n",
    "\n",
    "**P(Smoker∣Usesinsurance)= P(Usesinsurance)/P(Smoker∩Usesinsurance)**\n",
    "\n",
    "\n",
    "**From the information provided:**\n",
    "\n",
    "- P(Smoker ∩ Usesinsurance) is the probability that an employee is both a smoker and uses the health insurance plan, which is 40% of the employees who use the plan (0.4).\n",
    "\n",
    "- P(Usesinsurance) is the probability that an employee uses the health insurance plan, which is 70% of all employees (0.7).\n",
    "\n",
    "\n",
    "**Plugging in the values:**\n",
    "- P(Smoker∣Usesinsurance)= 0.4/0.7\n",
    "\n",
    "**So, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately 0.571 or 57.1%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929421e9-9984-4ed5-b524-7250e29dae02",
   "metadata": {},
   "source": [
    "#### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5c8b7-a9dd-4bd7-bf0f-a1e821e8f9d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of the Naive Bayes algorithm used for classification tasks, but they differ in terms of the type of data they are suitable for:\n",
    "\n",
    "**Bernoulli Naive Bayes:**\n",
    "\n",
    "- Suitable for binary or multivariate Bernoulli-distributed data.\n",
    "- Assumes that features are binary variables (0 or 1), representing the presence or absence of a particular term or feature.\n",
    "- Commonly used in text classification tasks, where the presence or absence of words in a document is considered.\n",
    "\n",
    "**Multinomial Naive Bayes:**\n",
    "\n",
    "- Suitable for discrete data, often used for document classification tasks.\n",
    "- Assumes that features represent the frequency of words or other discrete data (integer counts), and it works well when the data can be modeled with a multinomial distribution.\n",
    "\n",
    "**In summary, the main difference lies in the type of data they handle – Bernoulli Naive Bayes is for binary data, while Multinomial Naive Bayes is for discrete count data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e2d86-5d15-43c5-918b-91567d75b9b9",
   "metadata": {},
   "source": [
    "#### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7a839-8650-4a07-add5-c8ba90c6c581",
   "metadata": {},
   "source": [
    "**Bernoulli Naive Bayes typically handles missing values by considering them as a separate category. If a feature is missing for a particular instance, it is treated as a third category distinct from the presence (1) and absence (0) categories. This assumes that the missing values are not missing completely at random and may carry some information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa694596-cf91-4fa9-9fc5-f7476cec4eed",
   "metadata": {},
   "source": [
    "#### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24232cbe-b720-4156-ba8d-9bf70d9cb950",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes is generally suitable for binary and continuous data. For multi-class classification, where there are more than two classes, Gaussian Naive Bayes can still be used, but it requires extending the model to handle multiple classes. Each class would have its own set of mean and variance parameters for the features, and the class with the highest probability would be predicted.**\n",
    "\n",
    "- In summary, yes, Gaussian Naive Bayes can be adapted for multi-class classification by extending its parameters and calculations for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef748955-5309-442f-9019-24fbde0ada25",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:\n",
    "**Data preparation:**\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "- Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "**Results:**\n",
    "- Report the following performance metrics for each classifier:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "\n",
    "**Discussion:**\n",
    "- Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed? \n",
    "\n",
    "**Conclusion:**\n",
    "- Summarise your findings and provide some suggestions for future work.\n",
    "\n",
    "**Note: This dataset contains a binary classification problem with multiple features. The dataset is relatively small, but it can be used to demonstrate the performance of the different variants of Naive Bayes on a real-world problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753649b0-7a1c-4763-93f0-b9f0136e374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839380364047911, Precision: 0.8869617393737383, Recall: 0.8152389047416673, F1: 0.8481249015095276\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.7863496180326323, Precision: 0.7393175533565436, Recall: 0.7214983911116508, F1: 0.7282909724016348\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217730830896915, Precision: 0.7103733928118492, Recall: 0.9569516119239877, F1: 0.8130660909542995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Assume the last column is the target variable (spam or not)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Initialize classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Evaluate performance using cross-validation\n",
    "def evaluate_classifier(classifier, X, y):\n",
    "    accuracy = cross_val_score(classifier, X, y, cv=10, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(classifier, X, y, cv=10, scoring='precision').mean()\n",
    "    recall = cross_val_score(classifier, X, y, cv=10, scoring='recall').mean()\n",
    "    f1 = cross_val_score(classifier, X, y, cv=10, scoring='f1').mean()\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Get performance metrics for each classifier\n",
    "accuracy_bernoulli, precision_bernoulli, recall_bernoulli, f1_bernoulli = evaluate_classifier(bernoulli_nb, X, y)\n",
    "accuracy_multinomial, precision_multinomial, recall_multinomial, f1_multinomial = evaluate_classifier(multinomial_nb, X, y)\n",
    "accuracy_gaussian, precision_gaussian, recall_gaussian, f1_gaussian = evaluate_classifier(gaussian_nb, X, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_bernoulli}, Precision: {precision_bernoulli}, Recall: {recall_bernoulli}, F1: {f1_bernoulli}\")\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_multinomial}, Precision: {precision_multinomial}, Recall: {recall_multinomial}, F1: {f1_multinomial}\")\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_gaussian}, Precision: {precision_gaussian}, Recall: {recall_gaussian}, F1: {f1_gaussian}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88f960-d738-49a2-a757-b07bee5169bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
